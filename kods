import requests #Ielādē requests bibliotēku, lai veiktu HTTP pieprasījumus
from bs4 import BeautifulSoup #Ielādē BeautifulSoup HTML datu parsēšanai
from datetime import datetime #Ielādē datetime datumu formatēšanai un salīdzināšanai

BASE_URL = "https://quotes.toscrape.com"

def get_all_authors(): #Iegūst autorus no visām lapām
    authors = set() #Izveido tukšu kopu, lai glabātu unikālus autoru vārdus
    page = 1 #Sāk ar 1.lapu
    while True:
        res = requests.get(f"{BASE_URL}/page/{page}/") #Veic pieprasījumu uz konkrēto lapu
        if res.status_code != 200: #Pārtrauc ciklu, ja lapa nav atrasta
            break
        soup = BeautifulSoup(res.content, "html.parser")   #Parsē HTML saturu
        for author in soup.find_all("small", class_="author"): #Atrod visus autora elementus
            authors.add(author.text.strip()) #Pievieno autoru vārdus kopai
        if not soup.find("li", class_="next"): #Pārtrauc ciklu, ja nav nākamās lapas
            break
        page += 1 #pāriet uz nākamo lapu
    return sorted(authors) #Atgriež sakārtotu autoru sarakstu

def get_all_tags(): #Iegūst visus tagus no sākumlapas
    res = requests.get(BASE_URL) #Veic pieprasījumu uz sākumlapu
    if res.status_code != 200:
        return []
    soup = BeautifulSoup(res.content, "html.parser") #Parsē HTML
    tags = [tag.text.strip() for tag in soup.find_all("span", class_="tag-item")] #Iegūst visus tagus
    return sorted(tags) #Atgriež sakārtotu sarakstu

def get_author_quotes(author_name): #Iegūst konkrētā autora visus citātus
    quotes = []
    page = 1
    while True:
        res = requests.get(f"{BASE_URL}/page/{page}/")
        if res.status_code != 200:
            break
        soup = BeautifulSoup(res.content, "html.parser")
        for quote in soup.find_all("div", class_="quote"):
            author = quote.find("small", class_="author").text.strip()
            if author.lower() == author_name.lower(): #salīdzina autora vārdu, neatkarīgi no lielajiem burtiem
                text = quote.find("span", class_="text").text
                quotes.append(text) #Pievieno citātu sarakstam
        if not soup.find("li", class_="next"):  #Pārtrauc meklēšanas ciklu, ja vairs nav "Next" pogas
            break
        page += 1
    return quotes #Atgriež citātu sarakstu

def get_quotes_by_tag(tag): #Iegūst visus citātus no lapas pēc konkrēta taga
    quotes = [] #Sagatavo tukšu sarakstu, kurā glabāsies atrastie citāti
    page = 1 #Sāk ar pirmo lapu
    while True:
        res = requests.get(f"{BASE_URL}/tag/{tag}/page/{page}/") #Sūta pieprasījumu uz konkrēto taagu un lapu 
        if res.status_code != 200: #Pārtrauc ciklu, ja lapa nav pieejama
            break
        soup = BeautifulSoup(res.content, "html.parser") #Nolasīto HTML saturu padara Python saprotamu
        quote_divs = soup.find_all("div", class_="quote") #Atrod visus HTML blokus ar klasi "quote"
        if not quote_divs: #Pārtrauc ciklu, ja lapā nav neviena citāta
            break
        for quote in quote_divs: #Pāriet cauri katram citāta blokam lapā
            quotes.append(quote.find("span", class_="text").text) #Atrod citāta tekstu un pievieno to sarakstam
        if not soup.find("li", class_="next"): #Pārtrauc ciklu, ja nav "next" lapas poga
            break
        page += 1 #Ja ir nākamā lapa, palielina lapas numuru par 1 un turpina
    return quotes #Atgriež visus savāktos citātus, kā sarakstu

def get_author_info(author_name):
    page = 1
    while True:
        res = requests.get(f"{BASE_URL}/page/{page}/")
        if res.status_code != 200:
            break
        soup = BeautifulSoup(res.content, "html.parser")
        for quote in soup.find_all("div", class_="quote"):
            author = quote.find("small", class_="author").text.strip()
            if author.lower() == author_name.lower():
                link_tag = quote.find("a", href=lambda href: href and href.startswith("/author/"))
                if link_tag:
                    author_page = requests.get(BASE_URL + link_tag["href"])
                    if author_page.status_code == 200:
                        soup = BeautifulSoup(author_page.content, "html.parser")
                        birth_date = soup.find(class_="author-born-date").text
                        birth_place = soup.find(class_="author-born-location").text
                        desc = soup.find("div", class_="author-description").text.strip()
                        return {
                            "name": author,
                            "born": birth_date,
                            "place": birth_place,
                            "description": desc
                        }
        if not soup.find("li", class_="next"):
            break
        page += 1
    return None

def get_all_authors_with_birthdates():
    authors = {}
    page = 1
    seen = set()
    while True:
        res = requests.get(f"{BASE_URL}/page/{page}/")
        if res.status_code != 200:
            break
        soup = BeautifulSoup(res.content, "html.parser")
        for quote in soup.find_all("div", class_="quote"):
            name = quote.find("small", class_="author").text.strip()
            if name in seen:
                continue
            seen.add(name)
            link_tag = quote.find("a", href=lambda href: href and href.startswith("/author/"))
            if link_tag:
                author_page = requests.get(BASE_URL + link_tag["href"])
                if author_page.status_code == 200:
                    author_soup = BeautifulSoup(author_page.content, "html.parser")
                    try:
                        birth_date = author_soup.find(class_="author-born-date").text
                        birth_date_obj = datetime.strptime(birth_date, "%B %d, %Y")
                        authors[name] = birth_date_obj
                    except Exception:
                        continue
        if not soup.find("li", class_="next"):
            break
        page += 1
    return authors

# ==== CLI ====
while True:
    print("\n== Iespējas ==")
    print("1. Meklēt citātus pēc autora")
    print("2. Meklēt citātus pēc kategorijas")
    print("3. Parādīt informāciju par autoru")
    print("4. Sakārtot autorus no vecākā uz jaunāko")
    print("Ievadi 'stop' lai pārtrauktu\n")

    choice = input("Izvēlies opciju (1-4): ").strip().lower()

    if choice == "stop":
        print("Programma pārtraukta.")
        break

    elif choice == "1":
        authors = get_all_authors()
        for i, a in enumerate(authors, 1):
            print(f"{i}. {a}")
        author_input = input("Ievadi autora vārdu vai numuru: ").strip()
        if author_input.isdigit():
            idx = int(author_input) - 1
            if 0 <= idx < len(authors):
                author_input = authors[idx]
            else:
                print("Nepareizs numurs.")
                continue
        quotes = get_author_quotes(author_input)
        if quotes:
            print(f"\nCitāti no {author_input}:")
            for q in quotes:
                print(" -", q)
        else:
            print("Nav atrasti citāti.")

    elif choice == "2":
        tags = get_all_tags()
        for i, tag in enumerate(tags, 1):
            print(f"{i}. {tag}")
        tag_input = input("Ievadi tagu vai numuru: ").strip()
        if tag_input.isdigit():
            idx = int(tag_input) - 1
            if 0 <= idx < len(tags):
                tag_input = tags[idx]
            else:
                print("Nepareizs numurs.")
                continue
        quotes = get_quotes_by_tag(tag_input)
        if quotes:
            print(f"\nCitāti kategorijā '{tag_input}':")
            for q in quotes:
                print(" -", q)
        else:
            print("Nav atrasti citāti.")

    elif choice == "3":
        authors = get_all_authors()
        for i, a in enumerate(authors, 1):
            print(f"{i}. {a}")
        author_input = input("Ievadi autora vārdu vai numuru: ").strip()
        if author_input.isdigit():
            idx = int(author_input) - 1
            if 0 <= idx < len(authors):
                author_input = authors[idx]
            else:
                print("Nepareizs numurs.")
                continue
        info = get_author_info(author_input)
        if info:
            print(f"\nInformācija par {info['name']}:")
            print("Dzimis:", info["born"], info["place"])
            print("Apraksts:", info["description"])
        else:
            print("Autors nav atrasts.")

    elif choice == "4":
        authors = get_all_authors_with_birthdates()
        sorted_list = sorted(authors.items(), key=lambda x: x[1])
        print("\nAutori no vecākā uz jaunāko:")
        for i, (name, date) in enumerate(sorted_list, 1):
            print(f"{i}. {name} (dzimis {date.strftime('%Y-%m-%d')})")

    else:
        print("Nepareiza izvēle.")



